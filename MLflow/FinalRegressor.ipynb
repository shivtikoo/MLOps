{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e109fc9",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b75671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ShivTikoo\\envs\\CV_ClaimPrediction\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4552303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES FOR PREPROCESSING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#IMPORTING LIBRARIES FOR TRAINING\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "os.environ[\"GIT_PYTHON_REFRESH\"] = \"quiet\"\n",
    "import git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34d6cd",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO PREPROCESS AND LOAD THE TRAINING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d0c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO LOAD DATA\n",
    "def load_data(path):\n",
    "    data=pd.read_excel(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ce8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('C:/Users/Shiv.tikoo/Downloads/Project/Data/tmp_auto_poicies_202306261442.xlsx')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9189649",
   "metadata": {},
   "source": [
    "- TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f152059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df_new):\n",
    "    features = df_new.drop('clm_cnt',axis=1)   # Features\n",
    "    label = df_new['clm_cnt']  # Target variable\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(features, label, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82eb7e",
   "metadata": {},
   "source": [
    "- HANDLING THE NULL VALUES IN THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da521f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_null(df):\n",
    "    # NULL VALUES\n",
    "    print(\"na values available in data \\n\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # POLICY NUMBER WILL BE IRRELEVANT IN PREDICTION SO DROPPING\n",
    "    df=df.drop('policy_number',axis=1)\n",
    "    \n",
    "    # DROPPING IRRELEVANT RECORDS\n",
    "    df.drop_duplicates(keep='last',inplace=True)\n",
    "    \n",
    "    # DROPPING THE OUTLIERs \n",
    "    # df=df.drop(df[df['clm_cnt']>6].index)\n",
    "\n",
    "    # FILLING NA VALUES OF VEHICLE_SUBTYPE WITH THE MODE OF THAT VEHICLE_MAKE\n",
    "    df['vehicle_subtype']=df.groupby('vehicle_make')['vehicle_subtype'].transform(lambda x:x.fillna(x.mode().iloc[0]))\n",
    "    \n",
    "    # ASSUMING NAN CLAIM COUNT MEANING NO CLAIM HASNT BEEN TAKEN\n",
    "    df['clm_cnt']=df['clm_cnt'].fillna(0)\n",
    "    \n",
    "    # ASSUMING NO \n",
    "    df['hypo_party']=df['hypo_party'].fillna(\"self\")\n",
    "    \n",
    "    #CONSIDERING THERE WAS NO PREVIOUS INSURER AND DIGIT IS THE CUSTOMER'S FIRST INSURER\n",
    "    df['prev_insurer']=df['prev_insurer'].fillna(\"new\")\n",
    "    \n",
    "    df['veh_permit']=df.groupby('rto_location')['veh_permit'].transform(lambda x:x.fillna(x.mode().iloc[0]))\n",
    "    \n",
    "    # NULL VALUES\n",
    "    print(\"\\n na values POST PROCESING in data \\n\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68a311",
   "metadata": {},
   "source": [
    "- REMOVING THE BIAS OF THE DATAFRAME BY OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37c37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(df):\n",
    "    X = df.drop('clm_cnt', axis=1)  \n",
    "    Y = df['clm_cnt'] \n",
    "    \n",
    "    oversample = RandomOverSampler(sampling_strategy='auto')\n",
    "    X,Y = oversample.fit_resample(X,Y)\n",
    "    \n",
    "    df_new = pd.concat([X, Y], axis=1)\n",
    "\n",
    "    # Print the value counts of the target variable before and after oversampling\n",
    "    print(\"Before oversampling:\")\n",
    "    print(df['clm_cnt'].value_counts())\n",
    "\n",
    "    print(\"\\nAfter oversampling:\")\n",
    "    print(df_new['clm_cnt'].value_counts())\n",
    "    \n",
    "    print(\"\\nShape PRE oversampling:\")\n",
    "    print(df.shape)\n",
    "    \n",
    "    print(\"\\nShape POST oversampling:\")\n",
    "    print(df_new.shape)\n",
    "    \n",
    "    return df_new\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09246f9",
   "metadata": {},
   "source": [
    "- ENCODING THE DATAFRAME TO FIT VARIOUS REGRESSION MODELS ON IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a61576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df):\n",
    "    \n",
    "    print(\"DATA TYPE of FEATURES available in data \\n\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # PERFORMING FREQUENCY ENCODING\n",
    "    for x in df.columns:\n",
    "        if(df[x].dtype=='object'):\n",
    "            df_frequency_map = (df.groupby(x)['clm_cnt'].sum()/df[x].value_counts()).to_dict()\n",
    "            df[x] = df[x].map(df_frequency_map)   \n",
    "        \n",
    "    print(\"DATA TYPE of FEATURES post processing in data \\n\")\n",
    "    print(df.dtypes) \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89309ab",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO PREPROCESS THE TESTING DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93ad3f",
   "metadata": {},
   "source": [
    "- HANDLING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e0b9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_null_test(data):\n",
    "    \n",
    "    # DROP POLICY NUMBER\n",
    "    data=data.drop('policy_number',axis=1)\n",
    "    \n",
    "    # ASSUMING NO HYPO_PARTY MEANS THAT THE VEHICLE WAS SELF FINANCED\n",
    "    data['hypo_party']=data['hypo_party'].fillna(\"self\")\n",
    "    \n",
    "    #CONSIDERING THERE WAS NO PREVIOUS INSURER AND DIGIT IS THE CUSTOMER'S FIRST INSURER\n",
    "    data['prev_insurer']=data['prev_insurer'].fillna(\"new\")\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4963203",
   "metadata": {},
   "source": [
    "- ENCODING THE TEST DATAFRAME TO MAKE PREDICTIONS USING THE REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd984b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_testing_data(data, count_map):\n",
    "    \n",
    "    # Map the values in x_test to their encoded counterparts\n",
    "    x = data.copy()  # Make a copy of x_test\n",
    "    \n",
    "    \n",
    "    for j in x.columns:\n",
    "        if x[j].dtypes=='object':\n",
    "            x[j]=x[j].map(count_map[j]).fillna(0)\n",
    "            #need to put default values for certain columns\n",
    "            #new addition into the dictionary meaning no claim for it already exists so the default value being zero\n",
    "             \n",
    "        else:\n",
    "            x[j]=x[j]\n",
    "            \n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b918b",
   "metadata": {},
   "source": [
    "# MODEL TRAINING & METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fba8c",
   "metadata": {},
   "source": [
    "- FUNCTION TO MAKE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5233bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(model,X_test):\n",
    "    \n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred= np.round(Y_pred).astype(int)\n",
    "\n",
    "    # CHECKER FOR NEGATOVE VALUES\n",
    "    for i in range(len(Y_pred)):\n",
    "        if Y_pred[i]<0:\n",
    "            Y_pred[i]=0\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6def75",
   "metadata": {},
   "source": [
    "- FUNCTION TO GET METRICS OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b0ca562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(Y_test, Y_pred):\n",
    "    \n",
    "    Y_test=Y_test.fillna(0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(Y_test, Y_pred)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "    rmse = mean_squared_error(Y_test, Y_pred, squared=False)\n",
    "    print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "    r2=r2_score(Y_test,Y_pred)\n",
    "    print(\"R2 Score:\",r2)\n",
    "\n",
    "    mae=mean_absolute_error(Y_test,Y_pred)\n",
    "    print('Mean Absolute Error: ',mae)\n",
    "    \n",
    "    return {'Mean Squared Error': round(mse, 4), 'Root Mean Squared Error': round(rmse,4), 'R2 SCORE': round(r2, 4), 'Mean Absolute Error': round(mae, 4)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2297f01",
   "metadata": {},
   "source": [
    "- MAIN PIPELINE\n",
    "        \n",
    "    HANDLE NULL VALUES ->  REMOVE BIAS -> TRAIN TEST SPLIT -> PERFORM ENCODING ON THE TRAINING DATAFRAME\n",
    ".\n",
    "\n",
    "- PARALLEL PIPELINE\n",
    "    \n",
    "     CREATION OF DICTIONARY TO STORE MAPPINGS OF ENCODINGS MADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48e76bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na values available in data \n",
      "\n",
      "policy_number           0\n",
      "office_code             0\n",
      "policy_period           0\n",
      "imd_code                0\n",
      "imd_channel             0\n",
      "vehicle_make            0\n",
      "vehicle_model           0\n",
      "vehicle_subtype         0\n",
      "fuel_type               0\n",
      "rto_location            0\n",
      "veh_permit              0\n",
      "veh_age                 0\n",
      "prev_insurer       463816\n",
      "prev_ncb                0\n",
      "policy_type             0\n",
      "net_premium             0\n",
      "sum_insured             0\n",
      "hypo_party         246571\n",
      "clm_cnt            619679\n",
      "dtype: int64\n",
      "\n",
      " na values POST PROCESING in data \n",
      "\n",
      "office_code        0\n",
      "policy_period      0\n",
      "imd_code           0\n",
      "imd_channel        0\n",
      "vehicle_make       0\n",
      "vehicle_model      0\n",
      "vehicle_subtype    0\n",
      "fuel_type          0\n",
      "rto_location       0\n",
      "veh_permit         0\n",
      "veh_age            0\n",
      "prev_insurer       0\n",
      "prev_ncb           0\n",
      "policy_type        0\n",
      "net_premium        0\n",
      "sum_insured        0\n",
      "hypo_party         0\n",
      "clm_cnt            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = handling_null(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13adaca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clm_cnt']=df['clm_cnt'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19cbc5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling:\n",
      "clm_cnt\n",
      "0    483741\n",
      "1     20200\n",
      "2      1111\n",
      "3        77\n",
      "4         2\n",
      "5         2\n",
      "6         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling:\n",
      "clm_cnt\n",
      "1    483741\n",
      "2    483741\n",
      "3    483741\n",
      "4    483741\n",
      "5    483741\n",
      "6    483741\n",
      "0    483741\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shape PRE oversampling:\n",
      "(505134, 18)\n",
      "\n",
      "Shape POST oversampling:\n",
      "(3386187, 18)\n"
     ]
    }
   ],
   "source": [
    "df_new = sampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24d348d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275c506",
   "metadata": {},
   "source": [
    "- DICTIONARY FOR ENCODING THE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abc6b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_map={}\n",
    "\n",
    "y=X_train.copy()\n",
    "\n",
    "for x in y.columns:\n",
    "    if y[x].dtypes==\"object\":\n",
    "        count_map[x]=dict(y[x].value_counts())\n",
    " \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a335492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA TYPE of FEATURES available in data \n",
      "\n",
      "office_code          int64\n",
      "policy_period        int64\n",
      "imd_code             int64\n",
      "imd_channel         object\n",
      "vehicle_make        object\n",
      "vehicle_model       object\n",
      "vehicle_subtype     object\n",
      "fuel_type           object\n",
      "rto_location        object\n",
      "veh_permit          object\n",
      "veh_age              int64\n",
      "prev_insurer        object\n",
      "prev_ncb             int64\n",
      "policy_type         object\n",
      "net_premium        float64\n",
      "sum_insured          int64\n",
      "hypo_party          object\n",
      "dtype: object\n",
      "DATA TYPE of FEATURES post processing in data \n",
      "\n",
      "office_code          int64\n",
      "policy_period        int64\n",
      "imd_code             int64\n",
      "imd_channel          int64\n",
      "vehicle_make         int64\n",
      "vehicle_model        int64\n",
      "vehicle_subtype      int64\n",
      "fuel_type            int64\n",
      "rto_location         int64\n",
      "veh_permit           int64\n",
      "veh_age              int64\n",
      "prev_insurer         int64\n",
      "prev_ncb             int64\n",
      "policy_type          int64\n",
      "net_premium        float64\n",
      "sum_insured          int64\n",
      "hypo_party           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = encoding(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d2a4f",
   "metadata": {},
   "source": [
    "# NEW TRAINING PIPELINE\n",
    " \n",
    "- TRAIN TEST SPLIT \n",
    "- HANDLE NULL VALUES OF X_TRAIN \n",
    "- REMOVE BIAS OF THE DATAFRAME\n",
    "- PERFORM ENCODING OF THE CATEGORICAL COLUMNS\n",
    "\n",
    "    - MAKE DICTIONARY TO SAVE THE ENCODINGS MADE SO CAN USE IT TO ENCODE THE TESTING DATA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb6140bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_train, X_test, Y_train, Y_test = train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a6507aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new= pd.concat([X_train,Y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd2846b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na values available in data \n",
      "\n",
      "policy_number           0\n",
      "office_code             0\n",
      "policy_period           0\n",
      "imd_code                0\n",
      "imd_channel             0\n",
      "vehicle_make            0\n",
      "vehicle_model           0\n",
      "vehicle_subtype         0\n",
      "fuel_type               0\n",
      "rto_location            0\n",
      "veh_permit              0\n",
      "veh_age                 0\n",
      "prev_insurer       370882\n",
      "prev_ncb                0\n",
      "policy_type             0\n",
      "net_premium             0\n",
      "sum_insured             0\n",
      "hypo_party         197041\n",
      "clm_cnt            495707\n",
      "dtype: int64\n",
      "\n",
      " na values POST PROCESING in data \n",
      "\n",
      "office_code        0\n",
      "policy_period      0\n",
      "imd_code           0\n",
      "imd_channel        0\n",
      "vehicle_make       0\n",
      "vehicle_model      0\n",
      "vehicle_subtype    0\n",
      "fuel_type          0\n",
      "rto_location       0\n",
      "veh_permit         0\n",
      "veh_age            0\n",
      "prev_insurer       0\n",
      "prev_ncb           0\n",
      "policy_type        0\n",
      "net_premium        0\n",
      "sum_insured        0\n",
      "hypo_party         0\n",
      "clm_cnt            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_new = handling_null(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e7aa9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling:\n",
      "clm_cnt\n",
      "0.0    394203\n",
      "1.0     16353\n",
      "2.0       870\n",
      "3.0        69\n",
      "5.0         2\n",
      "6.0         1\n",
      "4.0         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling:\n",
      "clm_cnt\n",
      "0.0    394203\n",
      "1.0    394203\n",
      "2.0    394203\n",
      "3.0    394203\n",
      "5.0    394203\n",
      "6.0    394203\n",
      "4.0    394203\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shape PRE oversampling:\n",
      "(411499, 18)\n",
      "\n",
      "Shape POST oversampling:\n",
      "(2759421, 18)\n"
     ]
    }
   ],
   "source": [
    "df_new=sampling(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ed682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_map={}\n",
    "\n",
    "y=df_new.copy()\n",
    "\n",
    "for x in y.columns:\n",
    "    if y[x].dtypes==\"object\":\n",
    "        count_map[x]=dict(y.groupby(x)['clm_cnt'].sum()/y[x].value_counts())\n",
    " \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b69a3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA TYPE of FEATURES available in data \n",
      "\n",
      "office_code          int64\n",
      "policy_period        int64\n",
      "imd_code             int64\n",
      "imd_channel         object\n",
      "vehicle_make        object\n",
      "vehicle_model       object\n",
      "vehicle_subtype     object\n",
      "fuel_type           object\n",
      "rto_location        object\n",
      "veh_permit          object\n",
      "veh_age              int64\n",
      "prev_insurer        object\n",
      "prev_ncb             int64\n",
      "policy_type         object\n",
      "net_premium        float64\n",
      "sum_insured          int64\n",
      "hypo_party          object\n",
      "clm_cnt            float64\n",
      "dtype: object\n",
      "DATA TYPE of FEATURES post processing in data \n",
      "\n",
      "office_code          int64\n",
      "policy_period        int64\n",
      "imd_code             int64\n",
      "imd_channel        float64\n",
      "vehicle_make       float64\n",
      "vehicle_model      float64\n",
      "vehicle_subtype    float64\n",
      "fuel_type          float64\n",
      "rto_location       float64\n",
      "veh_permit         float64\n",
      "veh_age              int64\n",
      "prev_insurer       float64\n",
      "prev_ncb             int64\n",
      "policy_type        float64\n",
      "net_premium        float64\n",
      "sum_insured          int64\n",
      "hypo_party         float64\n",
      "clm_cnt            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_new=encoding(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c288e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_new.drop('clm_cnt',axis=1)   \n",
    "Y_train = df_new['clm_cnt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c5e0a",
   "metadata": {},
   "source": [
    "# MLFLOW EXPERIMENT LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec083134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFLOW\n",
    "\n",
    "def create_experiment(experiment_name,run_name,run_metrics,model,run_params=None):\n",
    "    \n",
    "    import mlflow\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        if not run_params==None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param,run_params[param])\n",
    "                \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric,run_metrics[metric])\n",
    "            \n",
    "            mlflow.sklearn.log_model(model,\"model\")\n",
    "            \n",
    "            print(\"Run - %s is logged to experiment- %s\" %(run_name,experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0dceb9",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c5c7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_lr(X_train,Y_train):\n",
    "    # Create an instance of LinearRegression\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075dede",
   "metadata": {},
   "source": [
    "- TRAINING & LOGGING LINEAR REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2536b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training_lr(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68360c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMING TEST DATA TO FIT THE MODEL\n",
    "X_test= handling_null_test(X_test)\n",
    "\n",
    "# Encode testing data using the encoding dictionaries  \n",
    "X_test = encode_testing_data(X_test, count_map)\n",
    "\n",
    "# Filling claim count null values with 0\n",
    "Y_test=Y_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93a9a882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.5791999875532874\n",
      "Root Mean Squared Error: 1.2566622408401102\n",
      "R2 Score: -37.89343976877271\n",
      "Mean Absolute Error:  0.9491162834116439\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ad0772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.5791999875532874\n",
      "Root Mean Squared Error: 1.2566622408401102\n",
      "R2 Score: -37.89343976877271\n",
      "Mean Absolute Error:  0.9491162834116439\n"
     ]
    }
   ],
   "source": [
    "experiment_name=\"NEW ENCODING LR\"\n",
    "run_name=\"Linear Regressor\"\n",
    "run_metrics=get_metrics(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7263a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41913 48396 30985  2384   264    25     5]\n",
      " [  761  1598  1666   249    43     1     0]\n",
      " [   41    66    99    32     6     5     0]\n",
      " [    0     2     0     1     3     1     1]\n",
      " [    0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "fig= confusion_matrix(Y_test,Y_pred)\n",
    "\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbf7e739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/19 14:37:52 INFO mlflow.tracking.fluent: Experiment with name 'NEW ENCODING LR' does not exist. Creating a new experiment.\n",
      "D:\\ShivTikoo\\envs\\CV_ClaimPrediction\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Linear Regressor is logged to experiment- NEW ENCODING LR\n",
      "Run - Linear Regressor is logged to experiment- NEW ENCODING LR\n",
      "Run - Linear Regressor is logged to experiment- NEW ENCODING LR\n",
      "Run - Linear Regressor is logged to experiment- NEW ENCODING LR\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2578c2",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2dc1f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_svr(X_train,Y_train):\n",
    "    \n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    # Create a Support Vector Regression model\n",
    "    model = linear_model.SGDRegressor()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fccbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_linsvr(X_train,Y_train):\n",
    "    \n",
    "    from sklearn.svm import LinearSVR\n",
    "    \n",
    "    # Create a Support Vector Regression model\n",
    "    model = LinearSVR()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b49381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a31dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training_svr(X_train_scaled,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1697552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.5807869433985748\n",
      "Root Mean Squared Error: 1.2572934993065759\n",
      "R2 Score: -37.932524224238044\n",
      "Mean Absolute Error:  0.9510144070697327\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predict_test(model,X_test_scaled)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "117152db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41644 48720 30911  2404   263    25     5]\n",
      " [  774  1590  1657   255    41     1     0]\n",
      " [   41    67    97    33     6     5     0]\n",
      " [    0     2     0     1     3     1     1]\n",
      " [    0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9ba7fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShivTikoo\\envs\\CV_ClaimPrediction\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=training_linsvr(X_train_scaled,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae278b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.7651849892647105\n",
      "Root Mean Squared Error: 1.3286026453626798\n",
      "R2 Score: -42.473984676935736\n",
      "Mean Absolute Error:  0.9844338301646077\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predict_test(model,X_test_scaled)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b6e9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43779 43744 30826  5213   299   103     8]\n",
      " [  852  1387  1606   391    67    15     0]\n",
      " [   47    56    85    42    11     7     1]\n",
      " [    0     1     1     1     2     2     1]\n",
      " [    0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1ff3ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Support Vector Regressor is logged to experiment- NEW ENCODING SVR\n",
      "Run - Support Vector Regressor is logged to experiment- NEW ENCODING SVR\n",
      "Run - Support Vector Regressor is logged to experiment- NEW ENCODING SVR\n",
      "Run - Support Vector Regressor is logged to experiment- NEW ENCODING SVR\n"
     ]
    }
   ],
   "source": [
    "experiment_name=\"NEW ENCODING SVR\"\n",
    "run_name=\"Support Vector Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972f369",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d131f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_xgr(X_train,Y_train):\n",
    "    \n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import make_scorer,mean_absolute_error\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.1, 0.01, 0.001]\n",
    "        # Add other hyperparameters specific to XGBoost Regressor\n",
    "    }\n",
    "\n",
    "    scoring=make_scorer(mean_absolute_error)\n",
    "    \n",
    "    # Create an instance of the XGBoost Regressor\n",
    "    model = xgb.XGBRegressor()\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    bestModel = RandomizedSearchCV(model, param_grid, cv=4, scoring=scoring)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    bestModel.fit(X_train,Y_train)\n",
    "\n",
    "    # Print the best hyperparameters and corresponding score\n",
    "    print(\"Best Hyperparameters: \", bestModel.best_params_)\n",
    "    print(\"Best Score: \", bestModel.best_score_)\n",
    "\n",
    "    # Return the best estimator\n",
    "    return bestModel.best_estimator_ , bestModel.best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d71fcd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.001}\n",
      "Best Score:  2.388575749897732\n",
      "Mean Squared Error: 0.5203425957618943\n",
      "Root Mean Squared Error: 0.7213477633998003\n",
      "R2 Score: -11.815294811867005\n",
      "Mean Absolute Error:  0.5193313003702897\n"
     ]
    }
   ],
   "source": [
    "model,run_params=training_xgr(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3151a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58615 65357     0     0     0]\n",
      " [ 1080  3238     0     0     0]\n",
      " [   54   195     0     0     0]\n",
      " [    0     8     0     0     0]\n",
      " [    0     1     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# CONFUSION MATRIX FOR VISUALIZATION\n",
    "from sklearn.metrics import confusion_matrix\n",
    "what=confusion_matrix(Y_test,Y_pred)\n",
    "print(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6460a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ShivTikoo\\envs\\CV_ClaimPrediction\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n"
     ]
    }
   ],
   "source": [
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756426e",
   "metadata": {},
   "source": [
    "- ADDING MORE VERSIONS TO THE MLFLOW MODEL REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cffe61ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.3442838472788375\n",
      "Root Mean Squared Error: 0.5867570598457572\n",
      "R2 Score: -7.479219340830303\n",
      "Mean Absolute Error:  0.32089958614680897\n",
      "[[86529 36166  1221    55     1]\n",
      " [ 1973  2192   142    11     0]\n",
      " [   86   144    16     2     1]\n",
      " [    2     1     5     0     0]\n",
      " [    1     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(n_estimators= 300, max_depth= 9, learning_rate= 0.1)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "188aa36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/19 15:47:38 INFO mlflow.tracking.fluent: Experiment with name 'NEW ENCODING XGR' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n"
     ]
    }
   ],
   "source": [
    "run_params={'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.1}\n",
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575302a",
   "metadata": {},
   "source": [
    "- NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "537a68d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2626334131997386\n",
      "Root Mean Squared Error: 0.5124777197105632\n",
      "R2 Score: -5.468285789045164\n",
      "Mean Absolute Error:  0.24628154463702276\n",
      "[[96205 26946   778    42     1]\n",
      " [ 2544  1674    91     9     0]\n",
      " [  114   122    10     2     1]\n",
      " [    3     2     3     0     0]\n",
      " [    1     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(n_estimators= 300, max_depth=11, learning_rate= 0.1)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9dff18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n"
     ]
    }
   ],
   "source": [
    "run_params={'n_estimators': 300, 'max_depth': 11, 'learning_rate': 0.1}\n",
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af535b",
   "metadata": {},
   "source": [
    "- NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10c93f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.18506705666365872\n",
      "Root Mean Squared Error: 0.43019420807776887\n",
      "R2 Score: -3.5579372329428764\n",
      "Mean Absolute Error:  0.17129788094719484\n",
      "[[106190  17140    608     34      0]\n",
      " [  3066   1175     69      8      0]\n",
      " [   148     90      8      2      1]\n",
      " [     3      3      2      0      0]\n",
      " [     1      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(n_estimators= 400, max_depth=13, learning_rate= 0.1)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc63b57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW ENCODING XGR\n"
     ]
    }
   ],
   "source": [
    "run_params={'n_estimators': 400, 'max_depth': 13, 'learning_rate': 0.1}\n",
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96695147",
   "metadata": {},
   "source": [
    "- NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf30d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(n_estimators= 500, max_depth=15, learning_rate= 0.1)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9f3ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_params={'n_estimators': 500, 'max_depth': 15, 'learning_rate': 0.1}\n",
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a462be",
   "metadata": {},
   "source": [
    "- NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(n_estimators= 600, max_depth=15, learning_rate= 0.1)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d144d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params={'n_estimators': 500, 'max_depth': 18, 'learning_rate': 0.1}\n",
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b1ecc",
   "metadata": {},
   "source": [
    "- NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb298cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(n_estimators= 800, max_depth=15, learning_rate= 0.1)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c126b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params={'n_estimators': 800, 'max_depth': 23, 'learning_rate': 0.1}\n",
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced5ff0",
   "metadata": {},
   "source": [
    "- LOGGING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee735707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Gradient Boosting Regressor is logged to experiment- NEW DATA XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW DATA XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW DATA XGR\n",
      "Run - Gradient Boosting Regressor is logged to experiment- NEW DATA XGR\n"
     ]
    }
   ],
   "source": [
    "experiment_name=\"NEW ENCODING XGR\"\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c91307d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ee63b",
   "metadata": {},
   "source": [
    "- TRAINING THE XGBOOST MODEL ON UNSEEN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3e73dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.29488937921164055\n",
      "Root Mean Squared Error: 0.5430371803216061\n",
      "R2 Score: -8.678263669692988\n",
      "Mean Absolute Error:  0.2805772556503071\n",
      "[[11999  4222   108]\n",
      " [  215   183    14]\n",
      " [   12    14     2]]\n"
     ]
    }
   ],
   "source": [
    "# MAKING PREDICTIONS\n",
    "ans_pred = predict_test(model,test_features)\n",
    "\n",
    "# GETTING METRICS FOR THE PREDICTIONS MADE\n",
    "run_metrics = get_metrics(test_ans, ans_pred)\n",
    "\n",
    "# CONFUSION MATRIX FOR VISUALIZATION\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=confusion_matrix(test_ans,ans_pred)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7a024",
   "metadata": {},
   "source": [
    "# RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a591b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_rf(X_train, Y_train):\n",
    "    \n",
    "    # define random parameters grid\n",
    "    n_estimators = [5,21,51,101,201] # number of trees in the random forest\n",
    "    max_features = [1.0, 'sqrt'] # number of features in consideration at every split\n",
    "    min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "    min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "    bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "                    'bootstrap': bootstrap\n",
    "                  }\n",
    "    \n",
    "    model=RandomForestRegressor()\n",
    "    \n",
    "    # Perform grid search for hyperparameter tuning\n",
    "    model_tuning = RandomizedSearchCV(estimator = model, param_distributions = random_grid,\n",
    "                                      n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "    \n",
    "    model_tuning.fit(X_train, Y_train)\n",
    "    \n",
    "    print ('Random grid: ', random_grid, '\\n')\n",
    "    \n",
    "    # print the best parameters\n",
    "    print ('Best Parameters: ', model_tuning.best_params_, ' \\n')\n",
    "\n",
    "    best_params = model_tuning.best_params_\n",
    "    \n",
    "    n_estimators = best_params['n_estimators']\n",
    "    min_samples_split = best_params['min_samples_split']\n",
    "    min_samples_leaf = best_params['min_samples_leaf']\n",
    "    max_features = best_params['max_features']\n",
    "    bootstrap = best_params['bootstrap']\n",
    "    \n",
    "    model_tuned = RandomForestRegressor(n_estimators = n_estimators, min_samples_split = min_samples_split,\n",
    "                                         min_samples_leaf= min_samples_leaf, max_features = max_features,\n",
    "                                         bootstrap=bootstrap) \n",
    "    model_tuned.fit( X_train, Y_train)\n",
    "    \n",
    "    return model_tuned,best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1891f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(n_estimators=101, min_samples_split= 6, min_samples_leaf= 1, max_features= 'sqrt', bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc2d48a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(bootstrap=False, max_features=&#x27;sqrt&#x27;, min_samples_split=6,\n",
       "                      n_estimators=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(bootstrap=False, max_features=&#x27;sqrt&#x27;, min_samples_split=6,\n",
       "                      n_estimators=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_features='sqrt', min_samples_split=6,\n",
       "                      n_estimators=101)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049323f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "model,best_params=training_rf(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb78e1",
   "metadata": {},
   "source": [
    "- ADDING MULTIPLE VERSIONS TO THE MODEL REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b02bf665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(n_estimators=101, min_samples_split= 8, max_features= 'sqrt', bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db329aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.005693714764971842\n",
      "Root Mean Squared Error: 0.07545670788585891\n",
      "R2 Score: 0.9985747591738768\n",
      "Mean Absolute Error:  0.005342287349498994\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "926ff010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94272  2379    65     3     0     0     0]\n",
      " [    0 95884   579    45     0     0     0]\n",
      " [    0     0 96533   431     0     0     0]\n",
      " [    0     0     0 97029     0     0     0]\n",
      " [    0     0     0     0 96897     0     0]\n",
      " [    0     0     0     0     0 96589     0]\n",
      " [    0     0     0     0     0     0 96532]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "862a63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params={'n_estimators':101, 'min_samples_split': 8, 'max_features': 'sqrt', 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name=\"NEW ENCODING RF\"\n",
    "run_name=\"Random Forest Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bde1b",
   "metadata": {},
   "source": [
    "- NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dde861ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(n_estimators=200, min_samples_split= 6, min_samples_leaf= 2, max_features= 'sqrt', bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c24e5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.007775700713781566\n",
      "Root Mean Squared Error: 0.08817993373654556\n",
      "R2 Score: 0.998053600054366\n",
      "Mean Absolute Error:  0.007409507440515742\n",
      "[[92894  3752    70     3     0     0     0]\n",
      " [    0 95867   596    45     0     0     0]\n",
      " [    0     0 96533   431     0     0     0]\n",
      " [    0     0     0 97029     0     0     0]\n",
      " [    0     0     0     0 96897     0     0]\n",
      " [    0     0     0     0     0 96589     0]\n",
      " [    0     0     0     0     0     0 96532]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e02f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n",
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n",
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n",
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n"
     ]
    }
   ],
   "source": [
    "best_params={'n_estimators':200, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}\n",
    "\n",
    "experiment_name=\"NEW DATA RF\"\n",
    "run_name=\"Random Forest Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bd8e2",
   "metadata": {},
   "source": [
    "- NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24487922",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(n_estimators=101, min_samples_split= 10, max_features= 'sqrt', bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ad60b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.005653846948930804\n",
      "Root Mean Squared Error: 0.07519206706116546\n",
      "R2 Score: 0.9985847388165909\n",
      "Mean Absolute Error:  0.005305372705016552\n",
      "[[94296  2356    64     3     0     0     0]\n",
      " [    0 95884   579    45     0     0     0]\n",
      " [    0     0 96533   431     0     0     0]\n",
      " [    0     0     0 97029     0     0     0]\n",
      " [    0     0     0     0 96897     0     0]\n",
      " [    0     0     0     0     0 96589     0]\n",
      " [    0     0     0     0     0     0 96532]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)\n",
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aeb38209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n",
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n",
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n",
      "Run - Random Forest Regressor is logged to experiment- NEW DATA RF\n"
     ]
    }
   ],
   "source": [
    "best_params={'n_estimators':150, 'min_samples_split': 8, 'max_features': 'sqrt', 'bootstrap': False}\n",
    "\n",
    "experiment_name=\"NEW DATA RF\"\n",
    "run_name=\"Random Forest Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d063d",
   "metadata": {},
   "source": [
    "- PREPROCESSING ON DATAFRAME SPECIFIC TO RF REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "511e6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_rf(X_train):\n",
    "    columns=[\"rto_location\",\"veh_permit\",\"hypo_party\",\"sum_insured\",\"office_code\",\"imd_code\",\"vehicle_subtype\",\"veh_age\",\"net_premium\"]\n",
    "    trial=X_train[columns]\n",
    "    \n",
    "    return trial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e41325",
   "metadata": {},
   "source": [
    "- TRAINING OF THE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4c650d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(n_estimators=101, min_samples_split= 6, min_samples_leaf= 1, max_features= 'sqrt', bootstrap= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f5cf4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial=preprocess_rf(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fbac80d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(bootstrap=False, max_features=&#x27;sqrt&#x27;, min_samples_split=6,\n",
       "                      n_estimators=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(bootstrap=False, max_features=&#x27;sqrt&#x27;, min_samples_split=6,\n",
       "                      n_estimators=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_features='sqrt', min_samples_split=6,\n",
       "                      n_estimators=101)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( trial, Y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "808e2410",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trial=preprocess_rf(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "65f83d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.007123049799331992\n",
      "Root Mean Squared Error: 0.0843981622983107\n",
      "R2 Score: 0.9982169705017588\n",
      "Mean Absolute Error:  0.006623963805929378\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predict_test(model,test_trial)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0d16398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93752  2854   107     6     0     0     0]\n",
      " [    5 95612   847    44     0     0     0]\n",
      " [    0     0 96504   460     0     0     0]\n",
      " [    0     0     0 97029     0     0     0]\n",
      " [    0     0     0     0 96897     0     0]\n",
      " [    0     0     0     0     0 96589     0]\n",
      " [    0     0     0     0     0     0 96532]]\n"
     ]
    }
   ],
   "source": [
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0ca8e",
   "metadata": {},
   "source": [
    "- ORIGINAL DATATSET TRAINED MODEL METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5f4fdf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.005696667936530437\n",
      "Root Mean Squared Error: 0.07547627399739892\n",
      "R2 Score: 0.9985740199410833\n",
      "Mean Absolute Error:  0.005362959550409162\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predict_test(model,X_test)\n",
    "run_metrics = get_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0789f476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94325  2331    60     3     0     0     0]\n",
      " [    0 95840   624    44     0     0     0]\n",
      " [    0     0 96504   460     0     0     0]\n",
      " [    0     0     0 97029     0     0     0]\n",
      " [    0     0     0     0 96897     0     0]\n",
      " [    0     0     0     0     0 96589     0]\n",
      " [    0     0     0     0     0     0 96532]]\n"
     ]
    }
   ],
   "source": [
    "fig=confusion_matrix(Y_test,Y_pred)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd32abf",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9030f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances=model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1c0e9c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE IMPORTANCES: \n",
      "rto_location:0.2260306366584007\n",
      "veh_permit:0.13551657452790172\n",
      "hypo_party:0.13222661942549896\n",
      "office_code:0.10981604300150269\n",
      "sum_insured:0.10088776425189987\n",
      "imd_code:0.08924670251661741\n",
      "vehicle_subtype:0.04777021515126693\n",
      "veh_age:0.04754357819681572\n",
      "net_premium:0.04657156675420492\n",
      "vehicle_model:0.0139937438642389\n",
      "policy_type:0.011776436708035866\n",
      "imd_channel:0.011597825440868365\n",
      "prev_insurer:0.011392723958900468\n"
     ]
    }
   ],
   "source": [
    "indices=np.argsort(importances)[::-1]\n",
    "print(\"FEATURE IMPORTANCES: \")\n",
    "x=0;\n",
    "for i in range(len(X_train.columns)):\n",
    "    if(x<=12):\n",
    "        x+=1\n",
    "        print(f\"{X_train.columns[indices[i]]}:{importances[indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20503dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name=\"NEW DATA RF\"\n",
    "run_name=\"Random Forest Regressor\"\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0932bea",
   "metadata": {},
   "source": [
    "- PREDICTIONS FOR UNSEEN DATA USING THE RF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_pred = predict_test(model,test_features)\n",
    "run_metrics = get_metrics(test_ans, ans_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd366316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test=confusion_matrix(test_ans,ans_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a44312da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15930,   398,     1],\n",
       "       [  363,    46,     3],\n",
       "       [   22,     5,     1]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c94d8",
   "metadata": {},
   "source": [
    "- NEW MODEL TRAINED ON TOP 8 FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28bd2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "newTest_features=preprocess_rf(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "34eba034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.050629137098216946\n",
      "Root Mean Squared Error: 0.22500919336377556\n",
      "R2 Score: -0.6616472913183715\n",
      "Mean Absolute Error:  0.04788598008229471\n"
     ]
    }
   ],
   "source": [
    "ans_pred = predict_test(model,newTest_features)\n",
    "run_metrics = get_metrics(test_ans, ans_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "78025bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15940   388     1]\n",
      " [  363    48     1]\n",
      " [   22     5     1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test=confusion_matrix(test_ans,ans_pred)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615202ab",
   "metadata": {},
   "source": [
    "#  ADDING THE MODELS TO THE MLFLOW MODEL REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e38770d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'NewData_XGR' already exists. Creating a new version of this model...\n",
      "2023/07/11 15:55:14 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: NewData_XGR, version 10\n",
      "Created version '10' of model 'NewData_XGR'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "run_name=\"Gradient Boosting Regressor\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    result = mlflow.register_model(\n",
    "        \"runs:/09e4677206524c88a5c36def165b6c73/model\",\n",
    "        \"NewData_XGR\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "807b85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'NewData_RF' already exists. Creating a new version of this model...\n",
      "2023/07/11 15:59:36 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: NewData_RF, version 6\n",
      "Created version '6' of model 'NewData_RF'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "run_name=\"Random Forest Regressor\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    result = mlflow.register_model(\n",
    "        \"runs:/1fb31800b853442cbb73dd52e6f708d2/model\",\n",
    "        \"NewData_RF\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bae85",
   "metadata": {},
   "source": [
    "# SETTING STAGES OF THE MODELS IN THE MLFLOW REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afdb88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1688103098374, current_stage='Production', description='', last_updated_timestamp=1688103138176, name='NewData_RF', run_id='5f1d45c6a221454a888238dc7364215a', run_link='', source='mlflow-artifacts:/229557385950538072/5f1d45c6a221454a888238dc7364215a/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"NewData_RF\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61fbe2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1688548242090, current_stage='Staging', description='', last_updated_timestamp=1688548253335, name='NewData_XGR', run_id='d3df4bc673f049f1af31681e0f0b055b', run_link='', source='mlflow-artifacts:/414263798559657782/d3df4bc673f049f1af31681e0f0b055b/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"NewData_XGR\",\n",
    "    version=2,\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336bf7e",
   "metadata": {},
   "source": [
    "# AUTOMATED PIPELINE TO COMPARE AND REGISTER THE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bfc0e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(data):\n",
    "    count_map={}\n",
    "\n",
    "    y=data.copy()\n",
    "\n",
    "    for x in y.columns:\n",
    "        if y[x].dtypes==\"object\":\n",
    "            count_map[x]=dict(y[x].value_counts())\n",
    " \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return count_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "153d4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset):\n",
    "    \n",
    "    #splitting the dataframe\n",
    "    features = dataset.drop('clm_cnt',axis=1)   # Features\n",
    "    labels = dataset['clm_cnt']  # Target variable\n",
    "    \n",
    "    loaded_model= mlflow.sklearn.load_model(model)\n",
    "\n",
    "    trained_model= loaded_model.fit(features,labels)\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb050920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset):\n",
    "    \n",
    "    #splitting the dataframe\n",
    "    features = dataset.drop('clm_cnt',axis=1)   # Features\n",
    "    labels = dataset['clm_cnt']  # Target variable\n",
    "    labels=labels.fillna(0)\n",
    "    \n",
    "    pred = model.predict(features)\n",
    "    pred= np.round(pred).astype(int)\n",
    "    \n",
    "    # CHECKER FOR NEGATiVE VALUES\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]<0:\n",
    "            pred[i]=0\n",
    "            \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    test=confusion_matrix(labels,pred)\n",
    "    print(test)\n",
    "    \n",
    "    mae=mean_absolute_error(labels,pred)\n",
    "    print('Mean Absolute Error: ',mae)\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f67bb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def select_best_model_from_registry(registry_uri, new_dataset):\n",
    "    \n",
    "    mlflow.set_tracking_uri(registry_uri)\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    #PREPROCESSING OF THE NEW DATAFRAME\n",
    "    data=handling_null(new_dataset)\n",
    "    mapping=target_encoding(data)\n",
    "    train_df=encoding(data)\n",
    "    train_df=sampling(train_df)\n",
    "    \n",
    "    #TESTING DATAFRAME\n",
    "    test_df=pd.read_csv('C:/Users/Shiv.tikoo/Downloads/Project/Data/tmp_auto_poicies_202306301517.csv')\n",
    "    \n",
    "    #TRANSFORMING TEST DATA TO FIT THE MODEL\n",
    "    test_df=drop_testing_data(test_df)\n",
    "    test_df=handling_null_test(test_df)\n",
    "\n",
    "    #TARGET ENCODING  \n",
    "    test_df = encode_testing_data(test_df, mapping)\n",
    "    \n",
    "\n",
    "    #ALL REGISTERED MODELS IN THE REGISTRY\n",
    "    all_models = client.search_model_versions(\"\", order_by=[\"creation_timestamp desc\" ])\n",
    "    best_model = None\n",
    "    best_metrics = None\n",
    "\n",
    "    for model in all_models:\n",
    "        model_name = model.name\n",
    "        model_version = model.version\n",
    "\n",
    "        # Load the model from the registry\n",
    "        model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "        loaded_model = mlflow.pyfunc.get_model_dependencies(model_uri)\n",
    "        \n",
    "        trained_model = train_model(model_uri,train_df)\n",
    "\n",
    "        # Evaluate the trained model using desired metrics\n",
    "        model_metrics = evaluate_model(trained_model, test_df)\n",
    "\n",
    "        if best_metrics is None or model_metrics < best_metrics:\n",
    "            best_model = model\n",
    "            best_metrics = model_metrics\n",
    "\n",
    "    if best_model:\n",
    "        # Set the best model to production in the registry\n",
    "        client.transition_model_version_stage(\n",
    "            name=best_model.name,\n",
    "            version=best_model.version,\n",
    "            stage=\"production\"\n",
    "        )\n",
    "        print(f\"The best model '{best_model.name}:{best_model.version}' has been set to PRODUCTION.\")\n",
    "    else:\n",
    "        print(\"No models found in the registry.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec769567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na values available in data \n",
      "\n",
      "policy_number           0\n",
      "office_code             0\n",
      "policy_period           0\n",
      "imd_code                0\n",
      "imd_channel             0\n",
      "vehicle_make            0\n",
      "vehicle_model           0\n",
      "vehicle_subtype         0\n",
      "fuel_type               0\n",
      "rto_location            0\n",
      "veh_permit              0\n",
      "veh_age                 0\n",
      "prev_insurer       463816\n",
      "prev_ncb                0\n",
      "policy_type             0\n",
      "net_premium             0\n",
      "sum_insured             0\n",
      "hypo_party         246571\n",
      "clm_cnt            619679\n",
      "dtype: int64\n",
      "\n",
      " na values POST PROCESING in data \n",
      "\n",
      "office_code        0\n",
      "policy_period      0\n",
      "imd_code           0\n",
      "imd_channel        0\n",
      "vehicle_make       0\n",
      "vehicle_model      0\n",
      "vehicle_subtype    0\n",
      "fuel_type          0\n",
      "rto_location       0\n",
      "veh_permit         0\n",
      "veh_age            0\n",
      "prev_insurer       0\n",
      "prev_ncb           0\n",
      "policy_type        0\n",
      "net_premium        0\n",
      "sum_insured        0\n",
      "hypo_party         0\n",
      "clm_cnt            0\n",
      "dtype: int64\n",
      "DATA TYPE of FEATURES available in data \n",
      "\n",
      "office_code          int64\n",
      "policy_period        int64\n",
      "imd_code             int64\n",
      "imd_channel         object\n",
      "vehicle_make        object\n",
      "vehicle_model       object\n",
      "vehicle_subtype     object\n",
      "fuel_type           object\n",
      "rto_location        object\n",
      "veh_permit          object\n",
      "veh_age              int64\n",
      "prev_insurer        object\n",
      "prev_ncb             int64\n",
      "policy_type         object\n",
      "net_premium        float64\n",
      "sum_insured          int64\n",
      "hypo_party          object\n",
      "clm_cnt            float64\n",
      "dtype: object\n",
      "DATA TYPE of FEATURES post processing in data \n",
      "\n",
      "office_code          int64\n",
      "policy_period        int64\n",
      "imd_code             int64\n",
      "imd_channel          int64\n",
      "vehicle_make         int64\n",
      "vehicle_model        int64\n",
      "vehicle_subtype      int64\n",
      "fuel_type            int64\n",
      "rto_location         int64\n",
      "veh_permit           int64\n",
      "veh_age              int64\n",
      "prev_insurer         int64\n",
      "prev_ncb             int64\n",
      "policy_type          int64\n",
      "net_premium        float64\n",
      "sum_insured          int64\n",
      "hypo_party           int64\n",
      "clm_cnt            float64\n",
      "dtype: object\n",
      "Before oversampling:\n",
      "clm_cnt\n",
      "0.0    483741\n",
      "1.0     20200\n",
      "2.0      1111\n",
      "3.0        77\n",
      "4.0         2\n",
      "5.0         2\n",
      "6.0         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling:\n",
      "clm_cnt\n",
      "1.0    483741\n",
      "2.0    483741\n",
      "3.0    483741\n",
      "4.0    483741\n",
      "5.0    483741\n",
      "6.0    483741\n",
      "0.0    483741\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shape PRE oversampling:\n",
      "(505134, 18)\n",
      "\n",
      "Shape POST oversampling:\n",
      "(3386187, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 16:03:49 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmptw2pv57z\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15751   577     1]\n",
      " [  337    72     3]\n",
      " [   20     7     1]]\n",
      "Mean Absolute Error:  0.057606297334366986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 16:21:55 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmp020_ro1q\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15929   400     0]\n",
      " [  355    54     3]\n",
      " [   22     5     1]]\n",
      "Mean Absolute Error:  0.0481245154749836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 16:31:48 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpdsvesqa0\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15735   594     0]\n",
      " [  336    73     3]\n",
      " [   21     6     1]]\n",
      "Mean Absolute Error:  0.05850080505695032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 16:51:58 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmp_egmj24l\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15927   402     0]\n",
      " [  357    52     3]\n",
      " [   23     4     1]]\n",
      "Mean Absolute Error:  0.04842268471584471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 17:02:56 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmptdhwtz6l\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15930   399     0]\n",
      " [  356    53     3]\n",
      " [   23     4     1]]\n",
      "Mean Absolute Error:  0.048184149323155824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 17:13:09 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpk0myjki1\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11230  4976   123]\n",
      " [  167   226    19]\n",
      " [    9    17     2]]\n",
      "Mean Absolute Error:  0.32458703560140734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 17:18:20 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmp7heb4qqk\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12841  3381   107]\n",
      " [  219   176    17]\n",
      " [   11    15     2]]\n",
      "Mean Absolute Error:  0.23066372473015684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 18:21:02 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmp53zzwzm0\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13519  2775    35]\n",
      " [  256   147     9]\n",
      " [   13    14     1]]\n",
      "Mean Absolute Error:  0.18784662174250105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 18:39:10 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpef5k_vkm\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14565  1717    47]\n",
      " [  298   105     9]\n",
      " [   17     9     2]]\n",
      "Mean Absolute Error:  0.12886874590017294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 19:02:58 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpqmksvejn\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15297  1028     4]\n",
      " [  337    68     7]\n",
      " [   19     8     1]]\n",
      "Mean Absolute Error:  0.08503786749358937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 19:42:27 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpp4e4damr\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15630   696     3]\n",
      " [  342    66     4]\n",
      " [   22     5     1]]\n",
      "Mean Absolute Error:  0.06541833144492815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 20:56:12 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpqh5pxgk5\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15717   607     5]\n",
      " [  355    54     3]\n",
      " [   23     3     2]]\n",
      "Mean Absolute Error:  0.0610650605283559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 21:50:28 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpn_ce0mh4\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15688   638     3]\n",
      " [  347    61     4]\n",
      " [   22     5     1]]\n",
      "Mean Absolute Error:  0.062257737491800344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 22:41:30 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpumi39j22\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12841  3381   107]\n",
      " [  219   176    17]\n",
      " [   11    15     2]]\n",
      "Mean Absolute Error:  0.23066372473015684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 22:54:36 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmpfqcu70cj\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15927   402     0]\n",
      " [  355    54     3]\n",
      " [   23     4     1]]\n",
      "Mean Absolute Error:  0.04830341701950027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 23:09:34 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r C:\\Users\\SHIV~1.TIK\\AppData\\Local\\Temp\\tmp5133rg80\\requirements.txt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10436  5712   181]\n",
      " [  152   228    32]\n",
      " [    8    16     4]]\n",
      "Mean Absolute Error:  0.37509690500327986\n",
      "The best model 'NewData_RF:5' has been set to PRODUCTION.\n"
     ]
    }
   ],
   "source": [
    "registry_uri = \"http://127.0.0.1:5000\"\n",
    "new_dataset = pd.read_excel('C:/Users/Shiv.tikoo/Downloads/Project/Data/tmp_auto_poicies_202306261442.xlsx')\n",
    "\n",
    "select_best_model_from_registry(registry_uri, new_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c8444",
   "metadata": {},
   "source": [
    "# MODEL SERVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da87862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVING THE MODEL FROM THE MODEL REGISTRY\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5006271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#BATCH PREDICTION\n",
    "\n",
    "X_test=drop_testing_data(X_test)\n",
    "\n",
    "# TRANSFORMING TEST DATA TO FIT THE MODEL\n",
    "X_test=handling_null_test(X_test)\n",
    "\n",
    "# Encode testing data using the encoding dictionaries  \n",
    "X_test = encode_testing_data(X_test, count_map)\n",
    "\n",
    "# Convert to list\n",
    "lst = X_test.values.tolist()\n",
    "\n",
    "inference_request = {\n",
    "        \"dataframe_records\": lst\n",
    "}\n",
    "endpoint = \"http://localhost:1568/invocations\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cf88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de238c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
